{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "__author__ = \"Jared Thompson\"\n",
    "\n",
    "\n",
    "class GradientDescent(object):\n",
    "    def __init__(self, fit_intercept=True, normalize=False, gradient=None, mu=None, sigma=None, ):\n",
    "        '''\n",
    "        INPUT: GradientDescent, boolean\n",
    "        OUTPUT: None\n",
    "        Initialize class variables. cost is the function used to compute the\n",
    "        cost.\n",
    "        '''\n",
    "        self.coeffs = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.normalize = normalize\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.alpha = None\n",
    "        self.gradient = gradient\n",
    "\n",
    "    def run(self, X, y, coeffs=None, alpha=0.01, num_iterations=100):\n",
    "        self.calculate_normalization_factors(X)\n",
    "        X = self.maybe_modify_matrix(X)\n",
    "        (self.coeffs,self.alpha) = (coeffs, alpha)\n",
    "        (M, N) = ( float(d) for d in X.shape)\n",
    "        if not np.any(self.coeffs):\n",
    "            self.coeffs = np.zeros(N)\n",
    "      \n",
    "        if self.fit_intercept:\n",
    "            self.coeffs = np.insert(self.coeffs, 0, 0)\n",
    "        \n",
    "        for i in xrange(num_iterations):\n",
    "            self.coeffs += alpha * self.gradient(X, y, self.coeffs)\n",
    "\n",
    "    def calculate_normalization_factors(self, X):\n",
    "        '''\n",
    "        INPUT: GradientDescent, 2 dimensional numpy array\n",
    "        OUTPUT: None\n",
    "        Initialize mu and sigma instance variables to be the numpy arrays\n",
    "        containing the mean and standard deviation for each column of X.\n",
    "        '''\n",
    "        self.mu = np.average(X, 0)\n",
    "        self.sigma = np.std(X, 0)\n",
    "        # Don't normalize intercept column\n",
    "        self.mu[self.sigma == 0] = 0\n",
    "        self.sigma[self.sigma == 0] = 1\n",
    "\n",
    "    def add_intercept(self, X):\n",
    "        '''\n",
    "        INPUT: 2 dimensional numpy array\n",
    "        OUTPUT: 2 dimensional numpy array\n",
    "        Return a new 2d array with a column of ones added as the first\n",
    "        column of X.\n",
    "        '''\n",
    "        return np.hstack((np.ones((X.shape[0], 1)), X))        \n",
    "\n",
    "    def maybe_modify_matrix(self, X):\n",
    "        '''\n",
    "        INPUT: GradientDescent, 2 dimensional numpy array\n",
    "        OUTPUT: 2 dimensional numpy array\n",
    "        Depending on the settings, normalizes X and adds a feature for the\n",
    "        intercept.\n",
    "        '''\n",
    "        if self.normalize:\n",
    "            X = (X - self.mu) / self.sigma\n",
    "        if self.fit_intercept:\n",
    "            return self.add_intercept(X)\n",
    "        return X\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "__author__ = \"Jared Thompson\"\n",
    "\n",
    "class LogisticRegression(object):\n",
    "\n",
    "    def __init__(self, fit_intercept = True, scale = True, norm = \"L2\"):\n",
    "        '''\n",
    "        INPUT: GradientDescent, function, function, function\n",
    "        OUTPUT: None\n",
    "\n",
    "        Initialize class variables. Takes three functions:\n",
    "        cost: the cost function to be minimized\n",
    "        gradient: function to calculate the gradient of the cost function\n",
    "        predict: function to calculate the predicted values (0 or 1) for\n",
    "        the given data\n",
    "        '''\n",
    "        gradient_choices = {None: self.cost_gradient, \"L1\": self.cost_gradient_lasso, \"L2\": self.cost_gradient_ridge}\n",
    "\n",
    "        self.alpha = None\n",
    "        self.gamma = None\n",
    "        self.coeffs = None\n",
    "        self.num_iterations = 0\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.scale = scale\n",
    "        self.normalize = False\n",
    "        if norm:\n",
    "            self.norm = norm\n",
    "            self.normalize = True\n",
    "        self.gradient = gradient_choices[norm]        \n",
    "        \n",
    "    def fit(self,  X, y, alpha=0.01, num_iterations=10000, gamma=0.):\n",
    "        '''\n",
    "        INPUT: 2 dimensional numpy array, numpy array, float, int, float\n",
    "        OUTPUT: numpy array\n",
    "\n",
    "        Main routine to train the model coefficients to the data\n",
    "        the given coefficients.\n",
    "        '''\n",
    "        (M, N) = (float(x) for x in X.shape)\n",
    "        (self.alpha, self.gamma) = (alpha, gamma)\n",
    "        self.num_iterations += num_iterations\n",
    "        self.coeffs = np.random.randn(N)\n",
    "        gradient = GradientDescent(self.fit_intercept, self.normalize, self.gradient)\n",
    "        gradient.run(X, y, self.coeffs, self.alpha, num_iterations)\n",
    "        self.coeffs = gradient.coeffs\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        INPUT: 2 dimensional numpy array, numpy array\n",
    "        OUTPUT: numpy array\n",
    "\n",
    "        Calculate the predicted values (0 or 1) for the given data with\n",
    "        the given coefficients.\n",
    "        '''\n",
    "        return np.around(self.hypothesis(X, self.coeffs)).astype(bool)\n",
    "\n",
    "    def hypothesis(self, X, coeffs):\n",
    "        '''\n",
    "        INPUT: 2 dimensional numpy array, numpy array\n",
    "        OUTPUT: numpy array\n",
    "\n",
    "        Calculate the predicted percentages (floats between 0 and 1)\n",
    "        for the given data with the given coefficients.\n",
    "        '''  \n",
    "        return 1. / (1. + np.exp(-X.dot(coeffs)))\n",
    "\n",
    "    def cost_function(self, X, y, coeffs):\n",
    "        '''\n",
    "        INPUT: 2 dimensional numpy array, numpy array, numpy array\n",
    "        OUTPUT: float\n",
    "\n",
    "        Calculate the value of the cost function for the data with the\n",
    "        given coefficients.\n",
    "        '''\n",
    "        h = self.hypothesis(X, coeffs)\n",
    "        (M, N) = (float(x) for x in X.shape)\n",
    "        return (1./M)* (y.dot(h) + (1 - y).dot(1 - h))\n",
    "\n",
    "    def cost_lasso(self, X, y, coeffs):\n",
    "        '''\n",
    "        INPUT: 2 dimensional numpy array, numpy array, numpy array\n",
    "        OUTPUT: float\n",
    "\n",
    "        Calculate the value of the cost function with lasso regularization\n",
    "        for the data with the given coefficients.\n",
    "        '''\n",
    "        h = self.hypothesis(X, coeffs)\n",
    "        (M, N) = (float(x) for x in X.shape)\n",
    "        return (1./M) * (y.dot(h) + (1 - y).dot(1 - h) + self.gamma * np.sum([np.abs(c) for c in coeffs]))\n",
    "\n",
    "    def cost_ridge(self, X, y, coeffs):\n",
    "        '''\n",
    "        INPUT: 2 dimensional numpy array, numpy array, numpy array\n",
    "        OUTPUT: float\n",
    "\n",
    "        Calculate the value of the cost function with ridge regularization\n",
    "        for the data with the given coefficients.\n",
    "        '''\n",
    "        h = self.hypothesis(X, coeffs)\n",
    "        (M, N) = (float(x) for x in X.shape)\n",
    "        return (1./M) * (y.dot(h) + (1 - y).dot(1 - h) + self.gamma * coeffs.dot(coeffs.T) / 2)\n",
    "\n",
    "    def cost_gradient(self, X, y, coeffs):\n",
    "        '''\n",
    "        INPUT: 2 dimensional numpy array, numpy array, numpy array\n",
    "        OUTPUT: numpy array\n",
    "\n",
    "        Calculate the gradient of the cost function at the given value\n",
    "        for the coeffs.\n",
    "\n",
    "        Return an array of the same size as the coeffs array.\n",
    "        '''\n",
    "        h = self.hypothesis(X, coeffs)\n",
    "        return X.T.dot(y - h)\n",
    "\n",
    "    def cost_gradient_lasso(self, X, y, coeffs):\n",
    "        '''\n",
    "        INPUT: 2 dimensional numpy array, numpy array, numpy array\n",
    "        OUTPUT: numpy array\n",
    "\n",
    "        Calculate the gradient of the cost function with regularization\n",
    "        at the given value for the coeffs.\n",
    "\n",
    "        Return an array of the same size as the coeffs array.\n",
    "        '''\n",
    "        h = self.hypothesis(X, coeffs)\n",
    "        weights = [c/np.abs(c) for c in coeffs[1:]]\n",
    "        weights.insert(0, 0)\n",
    "        return X.T.dot(y - h) + self.gamma * weights / N\n",
    "\n",
    "    def cost_gradient_ridge(self, X, y, coeffs):\n",
    "        '''\n",
    "        INPUT: 2 dimensional numpy array, numpy array, numpy array\n",
    "        OUTPUT: numpy array\n",
    "\n",
    "        Calculate the gradient of the cost function with regularization\n",
    "        at the given value for the coeffs.\n",
    "\n",
    "        Return an array of the same size as the coeffs array.\n",
    "        '''\n",
    "        (M, N) = (float(x) for x in X.shape)\n",
    "        h = self.hypothesis(X, coeffs)\n",
    "        weights = coeffs[1:]\n",
    "        weights = np.insert(weights, 0, 0)\n",
    "        return X.T.dot(y - h) + self.gamma * weights / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method LogisticRegression.cost_gradient_ridge of <__main__.LogisticRegression object at 0x108410190>>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                       n_clusters_per_class=2, n_samples=1000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train, gamma=0.1)\n",
    "\n",
    "X_test = np.hstack((np.zeros((X_test.shape[0], 1)), X_test)) \n",
    "probabilities = model.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(probabilities, y_test)\n",
    "\n",
    "plt.plot(np.asarray(fpr), np.asarray(tpr))\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity, Recall)\")\n",
    "plt.title(\"ROC plot of fake data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc_curve(probabilities, labels):\n",
    "    '''\n",
    "    INPUT: numpy array, numpy array\n",
    "    OUTPUT: list, list, list\n",
    "\n",
    "    Take a numpy array of the predicted probabilities and a numpy array of theau\n",
    "    true labels.\n",
    "    Return the True Positive Rates, False Positive Rates and Thresholds for the\n",
    "    ROC curve.\n",
    "    '''\n",
    "\n",
    "    '''#Following Algorithm 2 from\n",
    "    http://www.hpl.hp.com/techreports/2003/HPL-2003-4.pdf '''\n",
    "\n",
    "    '''#Initialize lists'''\n",
    "    TPRs = []\n",
    "    FPRs = []\n",
    "    treshholds = []\n",
    "\n",
    "    '''#Count number of positive and negative cases'''\n",
    "    num_pos_cases = list(labels).count(1)\n",
    "    num_neg_cases = list(labels).count(0)\n",
    "\n",
    "    '''#Sort probabilities by desc order'''\n",
    "    sorted_probabilities = sorted(probabilities, reverse=True)\n",
    "\n",
    "    '''#Sort indexes of probabilities by desc order,\n",
    "    this will help to match indices of labels'''\n",
    "    sorted_indices = np.argsort(probabilities)[::-1]\n",
    "    sorted_labels = labels[sorted_indices]\n",
    "\n",
    "    '''#Intialize true positives and false positives counter'''\n",
    "    '''#true positives'''\n",
    "    tp = 0.0\n",
    "    '''#false positives'''\n",
    "    fp = 0.0\n",
    "    '''#auxiliary var'''\n",
    "    prev_prob = float(\"inf\")\n",
    "\n",
    "    for prob in sorted_probabilities:\n",
    "\n",
    "        '''#Append values of prob into treshholds list '''\n",
    "        treshold = prob\n",
    "        treshholds.append(treshold)\n",
    "\n",
    "        for i, label in enumerate(sorted_labels):\n",
    "\n",
    "            '''#Check if prob of label is not equal to treshold '''\n",
    "            if probabilities[i] != prev_prob:\n",
    "                '''#if the index is not equal to zero then\n",
    "                append values into TPRs and FPRs lists'''\n",
    "                if i != 0:\n",
    "                    TPRs.append(tp/num_pos_cases)\n",
    "                    FPRs.append(fp/num_neg_cases)\n",
    "                '''Replace value of prev_prob with  prob of label[i] '''\n",
    "                prev_prob = probabilities[i]\n",
    "\n",
    "            '''#If label is positive then increase the counter of tp ,\n",
    "            otherwise increase the fp counter'''\n",
    "            if label == 1:\n",
    "                tp += 1.0\n",
    "            else:\n",
    "                fp += 1.0\n",
    "\n",
    "        '''#Calculate true positives rate and false negative rate '''\n",
    "\n",
    "        '''#true_positives= number correctly predicted\n",
    "        true positives/ number of positive cases'''\n",
    "        TPRs.append(tp/num_pos_cases)\n",
    "\n",
    "        '''#true_positives= number incorrectly predicted true positives/\n",
    "        number of negative cases'''\n",
    "        FPRs.append(fp/num_neg_cases)\n",
    "\n",
    "    return FPRs, TPRs, treshholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(a, b, c) = (1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
