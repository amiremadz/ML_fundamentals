{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 6003 Practicum 2: Regularized Logistic Regression and ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Exploration: Graduate School Admissions\n",
    "\n",
    "The data we will be using is admission data on Grad school acceptances.\n",
    "\n",
    "* `admit`: whether or not the applicant was admitted to grad school\n",
    "* `gpa`: undergraduate GPA\n",
    "* `GRE`: score of GRE test\n",
    "* `rank`: prestige of undergraduate school (1 is highest prestige)\n",
    "\n",
    "We will use the GPA, GRE, and rank of the applicants to try to predict whether or not they will be accepted into graduate school.\n",
    "\n",
    "Before we get to predictions, we should do some data exploration.\n",
    "\n",
    "**1)** Load the dataset into pandas: `data/grad.csv`.  \n",
    "\n",
    "\n",
    "**2)** Use the pandas `describe` method to get some preliminary summary statistics on the data. In particular look at the mean values of the features.  \n",
    "\n",
    "\n",
    "**3)** Use the pandas `crosstab` method to see how many applicants from each rank of school were accepted. You should get a dataframe that looks like this:\n",
    "\n",
    "    ```\n",
    "    rank    1   2   3   4\n",
    "    admit\n",
    "    0      28  ..  ..  ..\n",
    "    1      33  ..  ..  ..\n",
    "    ```\n",
    "\n",
    "\n",
    "**4)** Make a bar plot of the percent of applicants from each rank who were accepted. You can do `.plot(kind=\"bar\")` on a pandas dataframe.  \n",
    "    \n",
    "\n",
    "**5)** What does the distribution of the GPA and GRE scores look like? Do the distributions differ much?\n",
    "\n",
    "    Hint: Use the pandas `hist` method.  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Regularized Logistic Regression\n",
    "\n",
    "Now we're ready to try to fit our data with Regularized Logistic Regression.  \n",
    "\n",
    "In this part, we will use the gradient descent algorithm to estimate the logistic regression coefficients. \n",
    "\n",
    "The hypothesis function of the logistic regression is defined as, \n",
    "\n",
    "$$ h(x_i) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\beta_3 x_{i3})}} $$\n",
    "\n",
    "\n",
    "**1)** In `code/regularized_logistic_regression.py`, implement the `hypothesis` and `predict` functions. The `hypothesis` function will calculate the value of the hypothesis function for the given coefficients. (Remember to add a column of 1's to the feature meatrix.) This returns float values between 0 and 1. The `predict` function will round the hypothesis values so that you get a prediction of either 0 or 1. You can assume that the threshold we're using is 0.5, or you can set some other (logical) boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function without regularization is given by  \n",
    "\n",
    "$$ J(\\beta) = - \\frac{1}{n} \\sum_{i = 1}^{n} \\left[ y_i log(h(x_i)) + (1 - y_i) log(1 - h(x_i)) \\right] $$  \n",
    "\n",
    "With Ridge regularization, the cost function becomes  \n",
    "\n",
    "$$ J(\\beta) = - \\frac{1}{n} \\sum_{i = 1}^{n} \\left[ y_i log(h(x_i)) + (1 - y_i) log(1 - h(x_i)) \\right] + \\frac{\\lambda}{2n} \\sum_{j = 1}^{p} \\beta_j^2$$  \n",
    "\n",
    "**2)** In `regularized_logistic_regression.py`, implement `cost_function` (without regularization) and `cost_regularized` (with regularization) functions. You should be able to use the `hypothesis` function you implemented above.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The gradient of the cost function without regularization is given by  \n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\beta_j} J(\\beta) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( h(x_i) - y_i \\right) x_{ij}$$  \n",
    "\n",
    "where $j = 0, 1, 2, 3$ and $x_{i0} = 1$ for all $i$ (the column of 1's in the feature matrix).  \n",
    "\n",
    "\n",
    "With regularization, the gradient is  \n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\beta_0} J(\\beta) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( h(x_i) - y_i \\right) \\text{ when } j = 0$$  \n",
    "\n",
    "and  \n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\beta_j} J(\\beta) = \\frac{1}{n} \\sum_{i=1}^{n} \\left( h(x_i) - y_i \\right) x_{ij} + \\frac{\\lambda}{n} \\beta_j \\text{ for } j = 1, 2, 3$$\n",
    "\n",
    "\n",
    "\n",
    "**3)** In `regularized_logistic_regression.py`, implement `cost_gradient` (without regularization) and `gradient_regularized` (with regularization) functions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to implement gradient descent. Below is psuedocode for the gradient descent algorithm. In this pseudocode and in our implementation, we will stop after a given number of iterations. Another valid approach is to stop once the incremental improvement in the optimization function (the cost function) is sufficiently small.\n",
    "\n",
    "    Gradient Descent:\n",
    "        input: J: optimization function (cost function)\n",
    "               alpha: learning rate\n",
    "               n: number of iterations\n",
    "        output: local minimum of optimization function J\n",
    "\n",
    "        initialize b (often as all 0's)\n",
    "        repeat for n iterations:\n",
    "            update b as b - alpha * gradient(J)\n",
    "\n",
    "You are going to be completing the code stub in `gradient_descent.py`.\n",
    "\n",
    "**4)** Start by taking a look at the starter code. Note how the `GradientDescent` object is initialized. It takes a cost function and a gradient function. We will pass it the functions that we wrote above. Here's example code of how we'll be able to run the Gradient Descent code.\n",
    "\n",
    "    ```python\n",
    "    from regularized_logistic_regression import cost_regularized, gradient_regularized\n",
    "    gd = GradientDescent(cost_regularized, gradient_regularized, predict)\n",
    "    gd.run(X, y)\n",
    "    print \"coeffs:\", gd.coeffs\n",
    "    predictions = gd.predict(X)\n",
    "    ```\n",
    "\n",
    "\n",
    "\n",
    "**5)** Implement the `run` method. Follow the pseudocode from above.  \n",
    "\n",
    "\n",
    "**6)** Implement the `predict` method. It should just call the `predict` function that was taken as a parameter.  \n",
    "\n",
    "\n",
    "**7)** Run your version of gradient descent on the admission data.\n",
    "\n",
    "    **Note:** If you're having trouble getting it to converge, run it for just a few iterations and print out the cost at each iteration. The cost value should be going down. If it isn't, you might need to decrease your learning rate.\n",
    "    And of course check your implementation to make sure it's correct. You can also try printing out the cost every 100 iterations if you want to run it longer and not get an insane amount of printing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: ROC Curve \n",
    "\n",
    "One of the best ways to evaluate how a classifier performs is an ROC curve. (http://en.wikipedia.org/wiki/Receiver_operating_characteristic) \n",
    "\n",
    "![](images/roc_curve.png)\n",
    "\n",
    "To understand what is actually happening with an ROC curve, we can create one ourselves.  Here is pseudocode to plot it.\n",
    "\n",
    "The `probabilities` are the predicted probabilities in (0,1) returned from Logistic Regression. The standard default threshold is 0.5 where \n",
    "0-0.5 values are interpreted as the negative class ($y = 0$) and 0.5-1 values are predicted as the positive class ($y = 1$).\n",
    "\n",
    "The `labels` are the true/observed values of $y$.\n",
    "\n",
    "```\n",
    "def ROC_curve(probabilities, labels):\n",
    "    # Sort instances by their prediction strength (the probabilities)\n",
    "    # For every instance in increasing order of probability:\n",
    "        # Set the threshold to be the probability\n",
    "        # Set everything above the threshold to the positive class\n",
    "        # Calculate the True Positive Rate (aka sensitivity or recall)\n",
    "        # Calculate the False Positive Rate (1 - specificity)\n",
    "    Return three lists: TPRs, FPRs, thresholds\n",
    "```\n",
    "\n",
    "Recall that the *true positive rate* is\n",
    "\n",
    "```\n",
    " number of true positives     number correctly predicted positive\n",
    "-------------------------- = -------------------------------------\n",
    " number of positive cases           number of positive cases\n",
    "```\n",
    "\n",
    "and the *false positive rate* is\n",
    "\n",
    "```\n",
    " number of false positives     number incorrectly predicted positive\n",
    "--------------------------- = ---------------------------------------\n",
    "  number of negative cases           number of negative cases\n",
    "```\n",
    "\n",
    "You're going to be implementing the `roc_curve` function.\n",
    "\n",
    "Here's some example code that you should be able to use to plot the ROC curve with your function. This uses a fake dataset.\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           n_clusters_per_class=2, n_samples=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "probabilities = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "tpr, fpr, thresholds = roc_curve(probabilities, y_test)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity, Recall)\")\n",
    "plt.title(\"ROC plot of fake data\")\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Write an ROC curve function to compute the above in `roc_curve.py`.\n",
    "\n",
    "    It should take as input the predicted probabilities and the true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Run the above code to verify that it's working correctly. You can also validate your correctness against [scikit-learns built-in function](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Make a plot of the ROC curve for the regularized logistic regression model from Part 2.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** Is it possible to pick a threshold where TPR > 60% and FPR < 40%? What is the threshold?\n",
    "\n",
    "    Note that even if it appears to be in the middle of the graph it doesn't make the threshold 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** Say we are using this as a first step in the admission process. We want to weed out clearly unqualified candidates, but not reject too many candidates. What might be a good choice of threshold?\n",
    "\n",
    "    There isn't a single correct answer, so explain your choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
