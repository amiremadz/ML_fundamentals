{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 6003 4.1 RAT\n",
    "\n",
    "More review on the point of SVMs:\n",
    "\n",
    "1. What is the hypothesis of SVMs?\n",
    "2. What are the two principal advantages of SVMs over regression models?\n",
    "3. What is the prinicpal equation of SVMs? (hint: it includes the linear equation and response variable on the same side of the inequality) $?(?+?) \\geq 1$\n",
    "4. We need to figure out the $\\beta$ coefficients of the linear equation in the above equation. Recall that we also want to make them as small as possible, without making assumptions about collinearity. What type of regularization norm do we need to use?\n",
    "5. Now, we want to find the minimum of the $\\beta$ coefficients using the integral of the above norm as the function we are minimizing, **constrained by** the above prinicpal equation. How do we write the Lagrangian?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Two classes that can be separated by a plane (no other assumptions about variables required).\n",
    "2. 1) Handles unbalanced classes well 2) Model free\n",
    "3. $\\sum y_{i}(\\beta_{0}+\\beta^{T}x_{i}) \\geq 1$\n",
    "4. Ridge\n",
    "5. $\\Lambda(x,y, \\alpha, \\beta) = \\dfrac{1}{2}\\|\\beta\\|^{2} + \\sum \\alpha_{i} (1-y_{i}(\\beta_{0}+\\beta^{T}x_{i})) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
