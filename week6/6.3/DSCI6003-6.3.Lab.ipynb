{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Using the template below, write a class that implements a Gaussian Mixture model as per the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.stats import multivariate_normal \n",
    "import pylab\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def GaussianMixture(object):\n",
    "    def __init__(self, k, initial_means, initial_covs):\n",
    "        self.k = 2\n",
    "        self.means = initial_means\n",
    "        self.covs = initial_covs\n",
    "        self.norm = [None]*self.k\n",
    "        self._update_norms()\n",
    "        self.weights = None\n",
    "        self._alpha = 0.5\n",
    "        self.X = None\n",
    "        \n",
    "    def _update_norms(self):\n",
    "        #this fits each norm to the current mean and covariance for that norm\n",
    "        for index in range(self.k):\n",
    "            self.norm[index] = multivariate_normal(mean = self.means[index], \n",
    "                                                    cov = self.covs[index])\n",
    "            \n",
    "    def _expectation(self):\n",
    "        \n",
    "        # For all the data points in self.X, calculate the weighting of that datapoint using the _weight method defined\n",
    "        # below \n",
    "        \n",
    "        #Each x in self.X is assigned a weight based on the equation\n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _maximization(self):\n",
    "        \n",
    "        # Now calculate the weighting means and variance for each of the norms as given to you in the notes. \n",
    "        # Make sure to correctly calculate the weighting. Since there are only two norms, what does that mean?\n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _weight(self):\n",
    "        # Use self.norm[index].pdf(self.x) to calculate the phi as per the equation given to you in the notes. \n",
    "        # also use self.alpha\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _alpha():\n",
    "        \n",
    "        #calculate alpha by summation as given to you in the notes and save to self.alpha\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def train(self, X, threshold = .001):\n",
    "        \n",
    "        # Use the EM algorithm and the various methods you've implemented above to calculate the fit\n",
    "        \n",
    "        self.X = X\n",
    "        \n",
    "        # You will need to initialize the size of the weights list\n",
    "        \n",
    "        # Produce guesses at initial means and variances. These now get passed into the expectation step.\n",
    "        \n",
    "        # You want to use a while loop here and keep track of the number of loops the algorithm iterates through\n",
    "        \n",
    "        # Make sure to update self._alpha\n",
    "        \n",
    "        # If self.ll < threshold, exit the loop\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def log_likelihood(self):\n",
    "        \n",
    "        ll = 0\n",
    "        for i, x in enumerate(self.X):\n",
    "            ll += (1-weights[i])*np.log(x)+weights[i]*np.log(x)+\\\n",
    "            (1-weights[i])*np.log(self._alpha)+weights[i]*np.log(1.-self._alpha)\n",
    "    \n",
    "        self.ll = ll\n",
    "        return ll\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        # Assuming that you have correctly fit the data, given a new datapoint x, how would you \n",
    "        # return a label showing which of the two norms x belongs to?\n",
    "        \n",
    "        \n",
    "        #Returns a list of labels of length X.shape[0]\n",
    "        pass\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Replicate Hastie's results using his data. Alpha per iteration is given in the lecture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HastieData = [-0.39,0.12,0.94,1.67,1.76,2.44,3.72,4.28,4.92,5.53,0.06,0.48,1.01,1.68,1.80,3.25,4.12,4.60,5.28,6.22]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
